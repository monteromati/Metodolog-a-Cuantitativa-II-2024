---
title: "Taller 2"
format: html
bibliography: references.bib
---

![](logo-ie-ciae.gif){fig-align="left" width="200"}

# An√°lisis Inferencial Bivariado con Datos PISA 2009 üè´

En este taller, nos enfocaremos en realizar an√°lisis inferenciales bivariados utilizando datos de PISA 2009 para Chile. A lo largo de esta sesi√≥n, aprender√°s a aplicar diversas pruebas estad√≠sticas, como la prueba de Chi-Cuadrado, *U* de Mann-Whitney, la *H* de Kruskal-Wallis, la prueba *t* para muestras independientes, ANOVA, y las correlaciones (*r*) de Spearman y Pearson. Adem√°s, explorar√°s c√≥mo interpretar y reportar los resultados de estas pruebas, apoy√°ndote en visualizaciones gr√°ficas que facilitar√°n la comprensi√≥n de las relaciones entre variables.

## Instalaci√≥n de Paquetes

Comenzamos instalando los paquetes necesarios para esta sesi√≥n. Estos paquetes nos permitir√°n importar datos en formato SPSS, generar gr√°ficos, calcular pruebas estad√≠sticas como Chi-Cuadrado, y obtener estad√≠sticas descriptivas detalladas.

```{r message=FALSE, warning=FALSE}
options(repos = c(CRAN = "https://cran.rstudio.com/"))

install.packages("haven")    # Paquete para importar datos en formato SPSS
install.packages("ggplot2")  # Paquete para generar gr√°ficos
install.packages("gmodels")  # Paquete que contiene la funci√≥n CrossTable() para pruebas de Chi-Cuadrado
install.packages("psych")    # Paquete para obtener estad√≠sticos descriptivos m√°s detallados
install.packages("pastecs")  # Paquete para an√°lisis estad√≠stico b√°sico
install.packages("effsize")
```

## Carga de Bibliotecas

A continuaci√≥n, cargamos las bibliotecas de los paquetes que acabamos de instalar para hacer uso de sus funciones en el an√°lisis.

```{r message=FALSE, warning=FALSE}
library(haven)
library(ggplot2)
library(gmodels)
library(psych)
library(pastecs)
library(effsize)
```

## Configuraci√≥n del Directorio de Trabajo

Es importante definir el directorio de trabajo, que es la ubicaci√≥n donde se encuentran los datos que vamos a analizar. Primero verificamos el directorio actual y luego lo cambiamos al directorio donde se encuentran los datos.

```{r}
getwd()  # Verifica el directorio de trabajo actual

# Cambia el directorio de trabajo al lugar donde se guardaron los datos
setwd("G:/Mi unidad/Teaching/Metodolog√≠a Cuantitativa II 2024/Sesi√≥n 2")

getwd()  # Confirma que el directorio de trabajo ha cambiado
```

## Importaci√≥n de Datos

En esta secci√≥n, importamos los datos del archivo SPSS (.sav) a R utilizando el paquete `haven`, que convierte autom√°ticamente los datos en un data frame para facilitar su manipulaci√≥n y an√°lisis.

```{r}
pisa2009_chl <- read_sav("pisa2009_chl.sav")
View(pisa2009_chl)  # Visualiza la base de datos en una nueva ventana
```

## Exploraci√≥n Inicial de los Datos

Antes de realizar an√°lisis estad√≠sticos, es fundamental entender la estructura y contenido del conjunto de datos. Exploremos entonces brevemente el data frame, observando su clase, los primeros registros, los nombres de las variables, y obteniendo un resumen descriptivo b√°sico.

```{r}
class(pisa2009_chl)    # Verifica la clase del objeto 'pisa2009_chl'
head(pisa2009_chl)     # Muestra los primeros 6 casos de la base de datos
names(pisa2009_chl)    # Lista los nombres de las variables
dim(pisa2009_chl)      # Muestra el n√∫mero de variables y casos
summary(pisa2009_chl)  # Proporciona un resumen estad√≠stico para cada variable
str(pisa2009_chl)      # Muestra la estructura interna del data frame
```

## Prueba de Chi-Cuadrado (œá2)

La prueba de Chi-Cuadrado (œá2) es √∫til para evaluar si existe una asociaci√≥n estad√≠sticamente significativa entre dos variables categ√≥ricas. As√≠, inferimos estad√≠sticamente si dicha asociaci√≥n existe en la poblaci√≥n objetivo bajo un nivel de confianza (habitualmente con un 95%). En esta secci√≥n, analizaremos la relaci√≥n entre el g√©nero de los estudiantes y el tipo de establecimiento en el que estudian.

### An√°lisis Descriptivo para Variables Categ√≥ricas

Primero, generamos tablas de contingencia que muestran la distribuci√≥n de las variables categ√≥ricas de inter√©s. Estas tablas permiten observar la frecuencia y proporci√≥n de cada categor√≠a, tanto de manera individual como cruzada entre dos variables.

```{r}
# Tabla de contingencia para una variable categ√≥rica
table(pisa2009_chl$sex)  # Distribuci√≥n de g√©nero
table(pisa2009_chl$type) # Distribuci√≥n por tipo de establecimiento

# Tabla de contingencia para dos variables categ√≥ricas
table(pisa2009_chl$type, pisa2009_chl$sex)  # Distribuci√≥n conjunta de g√©nero y tipo de establecimiento

# Tabla de porcentajes para variables categ√≥ricas por grupo de inter√©s
# "margin = 2" entrega las proporciones de la distribuci√≥n condicional de la variable 1 seg√∫n la variable 2
prop.table(table(pisa2009_chl$type, pisa2009_chl$sex), margin = 2)
```

### Visualizaci√≥n de Variables Categ√≥ricas

Para visualizar la distribuci√≥n de las variables categ√≥ricas, generamos gr√°ficos de barras y gr√°ficos circulares.

```{r}
# Gr√°fico de Barras para la variable 'sex'
plot <- as.data.frame(table(pisa2009_chl$sex))
ggplot(plot, aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity")

# Gr√°fico de Barras para la variable 'type'
plot <- as.data.frame(table(pisa2009_chl$type))
ggplot(plot, aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity")

# Gr√°fico Circular para la variable 'sex'
plot <- as.data.frame(table(pisa2009_chl$sex))
ggplot(plot, aes(x = "", y = Freq, fill = Var1)) +
  geom_bar(stat = "identity", color = "white") +
  coord_polar("y", start = 0) +
  theme_void()

# Gr√°fico Circular para la variable 'type'
plot <- as.data.frame(table(pisa2009_chl$type))
ggplot(plot, aes(x = "", y = Freq, fill = Var1)) +
  geom_bar(stat = "identity", color = "white") +
  coord_polar("y", start = 0) +
  theme_void()
```

### Prueba de Chi-Cuadrado usando `CrossTable`

Veamos si existe una asociaci√≥n entre el g√©nero de los estudiantes y el tipo de establecimiento en el que estudian.

```{r}
# Generaci√≥n de la tabla de contingencia con la funci√≥n CrossTable
tabla <- CrossTable(pisa2009_chl$type, pisa2009_chl$sex, prop.chisq = FALSE)

# Guardamos las proporciones por columna
propcol <- tabla$prop.col

# Gr√°fico de Barras Condicional: Visualizaci√≥n de las proporciones condicionales
barplot(propcol, beside = TRUE, col = rainbow(3), ylim = c(0, 1))
legend('topright', c("Public", "Private government-dependent", "Private independent"), pch = 15, col = rainbow(3), cex = 0.7)
```

En este paso, visualizamos las proporciones condicionales de la variable `type` por cada categor√≠a de la variable `sex` para finalmente estimar un chi-cuadrado usando `CrossTable`.

```{r}
CrossTable(pisa2009_chl$type, pisa2009_chl$sex, prop.chisq = FALSE, chisq = TRUE, expected = TRUE, sresid = TRUE, format = "SPSS")
```

### Interpretaci√≥n de la Prueba de Chi-Cuadrado (œá2)

La prueba de œá2 nos permite verificar la hip√≥tesis nula de que no hay asociaci√≥n entre las variables `type` y `sex`. Ahora, es muy importante comprender c√≥mo se interpreta y reporta usando un estilo de escritura acad√©mica. Primero, debemos entender que si el valor *p* es lo suficientemente peque√±o (por convenci√≥n, *p* \< .05; *p* \< .01; *p* \< .001), se rechaza la hip√≥tesis nula. Bajo ese escenario, para nuestro ejemplo, esto indicar√≠a que el g√©nero de los estudiantes est√° asociado con el tipo de establecimiento en el que estudian. Segundo, para reportar en un informe es posible formularlo as√≠:

"Existe una asociaci√≥n estad√≠sticamente significativa entre el g√©nero de los estudiantes y la dependencia administrativa del establecimiento en el que estudian (*œá2*(2) = 11.40, *p* \< .01)."

Notar que en el par√©ntesis reportamos el valor del estad√≠stico *œá2*, seguido por los grados de libertad y el valor *p*.

### Prueba U de Mann-Whitney

La prueba U de Mann-Whitney es una prueba no param√©trica que se utiliza para comparar las diferencias entre dos grupos independientes cuando la variable de inter√©s no sigue una distribuci√≥n normal. En este caso, se usar√° para comparar el estatus socioecon√≥mico (estatus socioecon√≥mico) entre ni√±os y ni√±as.

-   Primero, aseguramos que las variables de inter√©s est√°n en formato num√©rico, lo cual es necesario para realizar la prueba.

```{r}
pisa2009_chl$ses <- as.numeric(pisa2009_chl$ses)  # Convierte estatus socioecon√≥mico a num√©rico
pisa2009_chl$sex <- as.numeric(pisa2009_chl$sex)  # Convierte sexo a num√©rico
```

-   **C√°lculo de Estad√≠sticos Descriptivos**: Obtenemos estad√≠sticas b√°sicas como la media, desviaci√≥n est√°ndar y varianza del estatus socioecon√≥mico (estatus socioecon√≥mico) para entender mejor la distribuci√≥n de la variable.

```{r}
# Estad√≠sticos b√°sicos
summary(pisa2009_chl$ses)  # Resumen descriptivo de estatus socioecon√≥mico
sd(pisa2009_chl$ses, na.rm = TRUE)  # Desviaci√≥n est√°ndar de estatus socioecon√≥mico
var(pisa2009_chl$ses, na.rm = TRUE)  # Varianza de estatus socioecon√≥mico

# Estad√≠sticos descriptivos m√°s detallados utilizando el paquete 'psych'
describe(pisa2009_chl$ses)
```

-   Adem√°s, calculamos estad√≠sticas descriptivas del estatus socioecon√≥mico por grupo de g√©nero.

```{r}
by(pisa2009_chl$ses, pisa2009_chl$sex, summary)
```

-   **Visualizaci√≥n de la Distribuci√≥n**: para comprender mejor la distribuci√≥n de los datos, generamos varios tipos de gr√°ficos, incluyendo histogramas, gr√°ficos de densidad y gr√°ficos cuartil-cuartil (Q-Q plot).

```{r}
# Histograma de estatus socioecon√≥mico
ggplot(pisa2009_chl, aes(x = ses)) +
  geom_histogram()

# Gr√°fico de Densidad de estatus socioecon√≥mico
ggplot(pisa2009_chl, aes(x = ses)) +
  geom_density()

# Histograma y Densidad combinados
ggplot(pisa2009_chl, aes(x = ses)) +
  geom_histogram(aes(y = ..density..)) +
  geom_density()

# Histograma de la variable 'math' como comparaci√≥n
ggplot(pisa2009_chl, aes(x = math)) +
  geom_histogram()
```

-   El gr√°fico cuartil-cuartil (Q-Q plot) nos ayuda a visualizar si la distribuci√≥n del estatus socioecon√≥mico sigue una distribuci√≥n normal. Si los puntos en el gr√°fico se distribuyen aproximadamente a lo largo de una l√≠nea diagonal, entonces se puede concluir que la variable se distribuye normalmente.

```{r}
# Gr√°fico cuartil-cuartil (Q-Q plot) para estatus socioecon√≥mico
qqnorm(pisa2009_chl$ses, main = 'Gr√°fico Cuartil-Cuartil')
qqline(pisa2009_chl$ses)
```

### Prueba de Normalidad Shapiro-Wilk

La prueba de Shapiro-Wilk eval√∫a formalmente si una muestra sigue una distribuci√≥n normal. Esto es importante para determinar si es apropiado usar pruebas param√©tricas o si es necesario utilizar alternativas no param√©tricas como la Prueba U de Mann-Whitney.

```{r}
# Prueba de normalidad Shapiro-Wilk para los primeros 5000 casos de estatus socioecon√≥mico
shapiro.test(pisa2009_chl$ses[0:5000])
```

Si el valor *p* de esta prueba es menor que 0.05, se rechaza la hip√≥tesis nula de normalidad, sugiriendo que los datos no siguen una distribuci√≥n normal.

#### Estimaci√≥n de la Prueba U de Mann-Whitney

Finalmente, realizamos la Prueba U de Mann-Whitney para comparar el estatus socioecon√≥mico entre ni√±os y ni√±as bajo la siguiente pregunta de investigaci√≥n: ¬øDifieren significativamente los ni√±os de las ni√±as en su estatus socioecon√≥mico? Y establecemos las siguientes hip√≥tesis estad√≠sticas:

-   **Hip√≥tesis nula (H0)**: No hay diferencia significativa en el estatus socioecon√≥mico entre ni√±os y ni√±as.
-   **Hip√≥tesis alternativa (H1)**: Hay una diferencia significativa en el estatus socioecon√≥mico entre ni√±os y ni√±as.

```{r}
prueba_u <- wilcox.test(pisa2009_chl$ses, pisa2009_chl$sex, paired = FALSE)
prueba_u
```

-   **Interpretaci√≥n de los Resultados**: Interpretamos los resultados de la prueba U de Mann-Whitney, donde el valor de *p* indica si podemos rechazar la hip√≥tesis nula de que no hay diferencias significativas entre los grupos.
    -   Si el valor de p es lo suficientemente peque√±o (*p* \< .05), se rechaza la hip√≥tesis nula.
    -   Esto indicar√≠a que el estatus socio-econ√≥mico de los estudiantes difiere significativamente entre ni√±os y ni√±as.
    -   **Reporte de Resultados**: Los ni√±os (Mdn = 1230) presentan significativamente menor estatus socioecon√≥mico que las ni√±as (Me = 1245, W = 7311835, *p* \< .001).

### Prueba *H* de Kruskal-Wallis

La prueba *H* de Kruskal-Wallis es una prueba no param√©trica utilizada para comparar m√°s de dos grupos independientes. Es una alternativa a ANOVA cuando no se cumple el supuesto de normalidad. En esta secci√≥n, la prueba se usar√° para evaluar si el estatus socioecon√≥mico de los estudiantes difiere seg√∫n el tipo de establecimiento al que asisten.

-   Primero, calculamos estad√≠sticas descriptivas b√°sicas del SES por cada tipo de establecimiento (type) para tener una idea preliminar de las diferencias entre los grupos.
-   Esta l√≠nea de c√≥digo genera res√∫menes estad√≠sticos (como la media y la mediana) del SES para cada categor√≠a del tipo de establecimiento, lo que ayuda a identificar posibles diferencias preliminares entre los grupos.

```{r}
by(pisa2009_chl$ses, pisa2009_chl$type, summary)
```

-   **Formulaci√≥n de la Pregunta de Investigaci√≥n**: la pregunta de investigaci√≥n que vamos a responder con la prueba H de Kruskal-Wallis es ¬ødifiere significativamente el estatus socioecon√≥mico de los estudiantes seg√∫n la dependencia del establecimiento al que asisten?
-   Formulamos las hip√≥tesis nula y alternativa:
    -   **H0**: El estatus socio-econ√≥mico de los estudiantes no difiere significativamente seg√∫n la dependencia del establecimiento al que asisten.
    -   **H1**: El estatus socio-econ√≥mico de los estudiantes s√≠ difiere significativamente seg√∫n la dependencia del establecimiento al que asisten.

#### Estimaci√≥n de la Prueba *H* de Kruskal-Wallis

Realizamos la prueba *H* de Kruskal-Wallis para determinar si hay diferencias significativas en el estatus socioecon√≥mico de los estudiantes seg√∫n el tipo de establecimiento. Esta l√≠nea de c√≥digo eval√∫a si las distribuciones del estatus socioeocn√≥mico son diferentes entre los grupos definidos por la variable `type` (tipo de establecimiento).

```{r}
kruskal.test(pisa2009_chl$ses ~ pisa2009_chl$type)
```

-   **Interpretaci√≥n de los Resultados**: interpretamos el estad√≠stico *H* y su valor de *p* resultante para determinar si podemos rechazar la hip√≥tesis nula. Si el valor de *p* es lo suficientemente peque√±o (*p* \< .05), se rechaza la hip√≥tesis nula. Esto indicar√≠a que existen diferencias significativas en el estatus socioecon√≥mico de los estudiantes seg√∫n la dependencia del establecimiento.
-   **Reporte de resultados**: El estatus socioecon√≥mico de los estudiantes difiere seg√∫n la dependencia del establecimiento al que asisten (*H*(2) = 422.54, *p* \< .001).

### Correlaci√≥n de Spearman (œÅ)

La correlaci√≥n de Spearman (œÅ) es una medida no param√©trica de la asociaci√≥n lineal entre dos variables ordinales o no normalmente distribuidas. En esta secci√≥n, utilizaremos la correlaci√≥n de Spearman para investigar si existe una asociaci√≥n significativa entre el estatus socioecon√≥mico de los estudiantes y su puntaje en matem√°ticas. La pregunta de investigaci√≥n que abordaremos es: ¬øExiste una asociaci√≥n significativa entre el estatus socio-econ√≥mico de los estudiantes y su puntaje en matem√°ticas? Y formulamos las hip√≥tesis nula y alternativa:

-   **H0**: El estatus socioecon√≥mico de los estudiantes no se asocia a los puntajes de matem√°ticas.
-   **H1**: El estatus socioecon√≥mico de los estudiantes s√≠ se asocia a los puntajes de matem√°ticas.

Antes de calcular la correlaci√≥n, es √∫til visualizar la relaci√≥n entre el estatus socioecon√≥mico y los puntajes en matem√°ticas para tener una idea preliminar de la posible asociaci√≥n. Estos gr√°ficos muestran la relaci√≥n entre estatus socioecon√≥mico y el puntaje en matem√°ticas, lo que nos permite observar si existe alg√∫n patr√≥n o tendencia entre las dos variables.

```{r}
# Visualizaci√≥n mediante un diagrama de dispersi√≥n (scatter plot)
pairs(pisa2009_chl$ses ~ pisa2009_chl$math)  # Muestra un gr√°fico de correlaci√≥n b√°sico

# Gr√°fico m√°s detallado utilizando ggplot2
ggplot(pisa2009_chl) +
  aes(x = ses, y = math) +
  geom_point(colour = "#0c4c8a") +
  theme_minimal()
```

#### C√°lculo de la Correlaci√≥n de Spearman

A continuaci√≥n, calculamos el coeficiente de correlaci√≥n de Spearman para evaluar la fuerza y direcci√≥n de la relaci√≥n entre estatus socioecon√≥mico y el puntaje en matem√°ticas. Esta l√≠nea de c√≥digo calcula el coeficiente de correlaci√≥n de Spearman (rho) junto con su valor de *p*, que indica si la correlaci√≥n es estad√≠sticamente significativa.

```{r}
cor.test(pisa2009_chl$ses, pisa2009_chl$math, method = "spearman", exact = FALSE)
```

-   **Interpretaci√≥n de los Resultados**: Finalmente, interpretamos el coeficiente de correlaci√≥n y el valor de *p* para determinar si existe una asociaci√≥n significativa entre las variables. Si el valor de p es lo suficientemente peque√±o (*p* \< .05), se rechaza la hip√≥tesis nula. Esto indica que existe una asociaci√≥n significativa entre el estatus socio-econ√≥mico y los puntajes en matem√°ticas.
-   **Reporte de resultados**: Existe una asociaci√≥n significativa y positiva entre el estatus socioecon√≥mico de los estudiantes y su puntaje en matem√°ticas (*œÅ* = .45, *p* \< .001), siendo una fuerza de asociaci√≥n moderada.
-   En este caso, si el coeficiente de Spearman es positivo y significativo, podemos concluir que a medida que aumenta el estatus socioecon√≥mico de los estudiantes, tambi√©n tienden a aumentar sus puntajes en matem√°ticas, y esta asociaci√≥n es estad√≠sticamente significativa.
-   Tambi√©n, interpretamos la magnitud o fuerza de asociaci√≥n entre ambas variables evaluando el estad√≠stico seg√∫n los criterios de \@cohen2013.
    -   **Correlaci√≥n peque√±a (baja)**: r ‚âà 0.10 a r = 0.29.
    -   **Correlaci√≥n moderada (media)**: r ‚âà 0.30 a r = 0.49.
    -   **Correlaci√≥n alta**: r ‚âà 0.50 a r = 1.00.
-   Estos valores proporcionan una orientaci√≥n general para interpretar la magnitud de la relaci√≥n entre dos variables. Es importante tener en cuenta que estos criterios son convenciones y deben interpretarse en el contexto espec√≠fico del campo de estudio.

### Prueba *t* de Diferencia de Medias para Muestras Independientes

La prueba *t* para muestras independientes se utiliza para comparar las medias de dos grupos independientes, en este caso, el puntaje en matem√°ticas entre ni√±os y ni√±as. Primero, obtenemos estad√≠sticas descriptivas b√°sicas del puntaje en matem√°ticas.

```{r}
summary(pisa2009_chl$math)
sd(pisa2009_chl$math)
var(pisa2009_chl$math)
```

-   Utilizamos la funci√≥n `describe()` del paquete `psych` para obtener un an√°lisis descriptivo m√°s detallado.

```{r}
describe(pisa2009_chl$math)
```

-   **Verificaci√≥n de Supuestos de Normalidad**: antes de realizar la prueba *t*, verificamos si la variable sigue una distribuci√≥n normal mediante varios m√©todos.

```{r}
# Histograma
ggplot(pisa2009_chl, aes(x=math)) +
  geom_histogram()

# Gr√°fico Cuartil-Cuartil (Q-Q plot):
qqnorm(pisa2009_chl$math, main='Gr√°fico Cuartil-Cuartil')
qqline(pisa2009_chl$math)

# Prueba de Shapiro-Wilk
shapiro.test(pisa2009_chl$math[0:5000])
```

-   **Prueba *t* de Diferencia de Medias**: realizamos la prueba *t* para determinar si hay diferencias significativas en el puntaje en matem√°ticas entre ni√±os y ni√±as.

```{r}
ind.t.test <- t.test(pisa2009_chl$math ~ pisa2009_chl$sex, var.equal = T)
ind.t.test
```

-   Obtenemos el estad√≠stico de *d* de Cohen para estimar el tama√±o de efecto que refleja la magnitud de esta diferencia de medias expresado en unidades de desviaci√≥n est√°ndar.

```{r}
d_cohen <- cohen.d(pisa2009_chl$math ~ pisa2009_chl$sex)
d_cohen
```

-   El valor de *d* de Cohen se interpreta de la siguiente manera:
    -   d ‚âà 0.2: Tama√±o de efecto peque√±o.
    -   d ‚âà 0.5: Tama√±o de efecto mediano.
    -   d ‚âà 0.8: Tama√±o de efecto alto.
-   **Reporte de Resultados**: En promedio, las ni√±as (M = 413.5) obtuvieron un puntaje de matem√°ticas significativamente menor que los ni√±os (M = 435.9), (*t*(5660.3) = 10.613, *p* \< .001). Esta diferencia representa un tama√±o de efecto de *d* = 0.282.

### An√°lisis de Varianza (ANOVA)

El an√°lisis de varianza (ANOVA) es una t√©cnica estad√≠stica utilizada para comparar las medias de tres o m√°s grupos independientes para determinar si al menos una de las medias es significativamente diferente de las dem√°s. En esta secci√≥n, utilizaremos ANOVA para analizar si el puntaje promedio en matem√°ticas de los estudiantes difiere seg√∫n la dependencia del establecimiento al que asisten. Antes de realizar el ANOVA, es √∫til visualizar la variaci√≥n entre y dentro de los grupos utilizando un diagrama de caja (boxplot). Esto nos permite observar la dispersi√≥n de los puntajes en matem√°ticas para cada tipo de establecimiento.

La siguiente l√≠nea de c√≥digo genera un gr√°fico que muestra la distribuci√≥n de los puntajes en matem√°ticas para cada tipo de establecimiento (type). Si las cajas se superponen significativamente, podr√≠a no haber diferencias claras entre los grupos.

```{r}
boxplot(pisa2009_chl$math ~ pisa2009_chl$type,
        xlab = "Dependencia", ylab = "Puntaje Pisa Mat")
```

La pregunta de investigaci√≥n que abordaremos con el ANOVA es la siguiente: dDifiere significativamente el puntaje promedio en matem√°ticas de los estudiantes seg√∫n la dependencia del establecimiento al que asisten? Y formulamos las hip√≥tesis nula y alternativa:

-   **H0**: No hay diferencias significativas en los puntajes promedios de matem√°ticas entre estudiantes en establecimientos de distintas dependencias.
-   **H1**: No todos los promedios son iguales.

Estimamos un modelo ANOVA utilizando la funci√≥n `aov()` para determinar si existen diferencias significativas en los puntajes promedios de matem√°ticas entre los diferentes tipos de establecimientos.

```{r}
res_an <- aov(pisa2009_chl$math ~ pisa2009_chl$type)
summary(res_an)
```

-   La funci√≥n `aov()` calcula el estad√≠stico *F*, que compara la variabilidad entre las medias de los grupos con la variabilidad dentro de los grupos. El resumen `summary(res_an)` proporcionar√° el valor del estad√≠stico *F* y su significancia.
-   **Interpretaci√≥n de los Resultados**: Interpretamos el valor del estad√≠stico *F* y el valor p para determinar si podemos rechazar la hip√≥tesis nula. Si el valor de p es lo suficientemente peque√±o (*p* \< .05), se rechaza la hip√≥tesis nula. Esto indica que existen diferencias significativas en los puntajes promedio de matem√°ticas entre los diferentes tipos de establecimientos.
-   **Reporte de Resultados**: El puntaje promedio de los estudiantes en matem√°ticas difiere seg√∫n la dependencia del establecimiento al que asisten (*F*(1, 4479) = 243.2, *p* \< .001).
-   En este caso, si el valor *p* es menor que .05, podemos concluir que al menos uno de los grupos tiene un puntaje promedio en matem√°ticas significativamente diferente de los otros, lo que sugiere que la dependencia del establecimiento est√° asociado a los puntajes de los estudiantes.

### Correlaci√≥n de Pearson (*r*)

La correlaci√≥n de Pearson (*r*) es una medida que eval√∫a la fuerza y la direcci√≥n de la asociaci√≥n lineal entre dos variables continuas. En esta secci√≥n, utilizaremos la correlaci√≥n de Pearson para investigar si existe una asociaci√≥n significativa entre los puntajes en matem√°ticas y los puntajes en lectura de los estudiantes. La pregunta de investigaci√≥n que abordaremos es la siguiente: ¬øexiste una asociaci√≥n significativa entre el puntaje en matem√°ticas y el puntaje en lectura de los estudiantes? Y formulamos las hip√≥tesis nula y alternativa:

-   **H0**: Los puntajes en lectura de los estudiantes no se asocian significativamente a los puntajes de matem√°ticas.
-   **H1**: Los puntajes en lectura de los estudiantes s√≠ se asocian significativamente a los puntajes de matem√°ticas.

Antes de calcular la correlaci√≥n de Pearson, es √∫til visualizar la relaci√≥n entre las dos variables para observar si existe una relaci√≥n de forma lineal.

```{r}
pairs(pisa2009_chl$math ~ pisa2009_chl$read)

# Gr√°fico m√°s detallado utilizando ggplot2
ggplot(pisa2009_chl) +
  aes(x = math, y = read) +
  geom_point(colour = "#0c4c8a") +
  theme_minimal()

```

-   Estos gr√°ficos muestran la relaci√≥n entre los puntajes en matem√°ticas y lectura. Si los puntos se alinean en una tendencia lineal (ascendente o descendente), entonces sugiere una correlaci√≥n entre las dos variables.
-   Calculamos una correlaci√≥n de Pearson para cuantificar la fuerza y la direcci√≥n de la relaci√≥n entre los puntajes en matem√°ticas y en lectura.

```{r}
r <- cor.test(pisa2009_chl$math, pisa2009_chl$read, method = "pearson")
r
```

La funci√≥n `cor.test()` devuelve el coeficiente de correlaci√≥n *r* junto con el valor *p*, que indica si la correlaci√≥n es estad√≠sticamente significativa.

-   **C√°lculo del Coeficiente de Determinaci√≥n** (*r¬≤*): es una medida que indica qu√© proporci√≥n de la variabilidad en una de las variables se puede explicar por la otra variable.

```{r}
r2 <- r$estimate * r$estimate
r2
```

-   El *r¬≤* proporciona una interpretaci√≥n adicional de la correlaci√≥n, indicando la proporci√≥n de la variabilidad compartida entre las dos variables. Si lo multiplicas por 100, entonces puedes interpretarlo como un porcentaje.
-   **Interpretaci√≥n de los Resultados**: interpretamos el coeficiente de correlaci√≥n y el valor *p* para determinar si existe una asociaci√≥n significativa entre las variables. Si el valor *p* es lo suficientemente peque√±o (*p* \< .05), se rechaza la hip√≥tesis nula. Esto indica que existe una asociaci√≥n significativa entre los puntajes en matem√°ticas y lectura.
-   **Reporte de Resultados**: Existe una asociaci√≥n significativa, positiva y alta entre los puntajes de lectura y los puntajes en matem√°ticas (*r* = .83, *p* \< .001). Los puntajes en matem√°ticas explican un 69% de los puntajes en lenguaje.
-   En este caso, si el valor *r* es positivo y significativo, podemos concluir que a medida que los puntajes en lectura aumentan, tambi√©n a aumentan los puntajes en matem√°ticas, y esta asociaci√≥n es estad√≠sticamente significativa.
-   *r¬≤* nos indica que aproximadamente el 69% de la variabilidad en los puntajes en lectura puede explicarse por los puntajes en matem√°ticas.

#### Generaci√≥n de una Tabla de Correlaci√≥n para M√∫ltiples Variables

Si deseas observar las correlaciones entre m√∫ltiples variables, puedes generar una tabla de correlaci√≥n. Esta l√≠nea de c√≥digo gener una tabla y muestra las correlaciones entre las variables seleccionadas, lo que puede ser √∫til para explorar relaciones adicionales en los datos.

```{r}
round(cor(pisa2009_chl[, 7:9]), digits = 2)  # Redondea a dos decimales
```
